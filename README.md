# Machine-Learning-Deep-Learning-Summary
#### &#160; &#160; &#160; &#160;**机器学习/深度学习知识点总结**

&#160; &#160; &#160; &#160;关于在ML/DL方面的知识点做一个总结，有些知识点会给出个人非常喜欢的博客链接详解，有些会给出我自己的博客。

&#160; &#160; &#160; &#160;++***持续更新中...***++

#### &#160; &#160; &#160; &#160;一、机器学习

##### &#160; &#160; &#160; &#160;1. Logistic Regression

&#160; &#160; &#160; &#160;![image](https://github.com/HuiZhou-xmu/Machine-Learning-Deep-Learning-Summary/raw/master/img/logistic_regression.png)

&#160; &#160; &#160; &#160;Logistic Regression是在Linear Regression基础上加了一个logistic函数，这样可以得到一个概率值，从而将回归变成了分类。

&#160; &#160; &#160; &#160;那么，**Logistic Regression和Linear Regression的区别是什么呢？**

&#160; &#160; &#160; &#160;区别如下：

&#160; &#160; &#160; &#160;**· 线性回归是拟合，逻辑斯蒂回归是分类。**

&#160; &#160; &#160; &#160;**· 线性回归使用最小二乘法最小化预测值和真实值之间的差距，逻辑斯蒂回归使用最大似然估计计算使得数据出现的可能性最大的参数。**

&#160; &#160; &#160; &#160;**· 逻辑斯蒂回归是在线性回归的基础上，加了一层logistic函数(又叫sigmoid函数)做了一层转换，使得输出压缩到0-1之间，这样0-0.5为1类，0.5-1为2类。**

&#160; &#160; &#160; &#160;那么继续思考，**为什么使用logistic函数？**

&#160; &#160; &#160; &#160;比如说，假设x>0时y=1(1类)，x<=0时y=0(2类)，那么画这个函数，就是一个阶跃函数，在0点这个分界点处发生了阶跃，有从0到1的突变，导致这点不连续，在数学上处理起来不太方便。

&#160; &#160; &#160; &#160;这时，引入logistic函数，如下：

&#160; &#160; &#160; &#160;![image](https://github.com/HuiZhou-xmu/Machine-Learning-Deep-Learning-Summary/raw/master/img/logistic_func.png)

&#160; &#160; &#160; &#160;优点如下：

&#160; &#160; &#160; &#160;**· 输入范围是−∞→+∞ ，而输出范围在0~1之间，满足我们对输入和输出的要求。**

&#160; &#160; &#160; &#160;**· logsitic函数接近于单位阶跃函数，而且是一个连续函数，且单调可微，优化起来更加简单。**

##### &#160; &#160; &#160; &#160;2. SVM

&#160; &#160; &#160; &#160;可以看这篇博客的详解：https://www.cnblogs.com/steven-yang/p/5658362.html

&#160; &#160; &#160; &#160;





